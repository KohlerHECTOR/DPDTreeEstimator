{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# A Pathological Dataset\nA Dataset where the base :class:`sklearn.tree.DecisionTreeClassifier` fails.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from time import time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom dpdt import DPDTreeClassifier\n\n\ndef create_pathological_dataset(n_samples=1000):\n    # Generate random points\n    X = np.random.default_rng(42).random((n_samples, 2))\n    y = np.zeros(n_samples)\n\n    # Define regions for class 1 (checkerboard pattern)\n    class_1_mask = (\n        ((X[:, 0] < 0.5) & (X[:, 1] < 0.5))\n        | ((X[:, 0] >= 0.5) & (X[:, 1] >= 0.5))\n        | ((X[:, 0] < 0.25) & (X[:, 1] >= 0.5))\n        | ((X[:, 0] >= 0.75) & (X[:, 1] < 0.5))\n    )\n\n    # Assign labels\n    y[class_1_mask] = 1\n\n    return X, y\n\n\n# Create dataset\nx, y = create_pathological_dataset(10_000)\n\n# Create meshgrid\nfeature_1, feature_2 = np.meshgrid(\n    np.linspace(x[:, 0].min(), x[:, 0].max()), np.linspace(x[:, 1].min(), x[:, 1].max())\n)\ngrid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\n\ncm = plt.cm.RdBu\ncm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n\n# Create figure with 3 subplots\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(16, 3))\n\n# Plot 1: Pathological dataset\nax1.scatter(x[:, 0], x[:, 1], c=y, cmap=cm_bright, edgecolor=\"black\")\nax1.set_title(\"Pathological Dataset\")\nax1.set_xlim(0, 1)\nax1.set_ylim(0, 1)\nax1.set_xticks(())\nax1.set_yticks(())\n\n# Plot 2: DecisionTreeClassifier\nstart = time()\ntree = DecisionTreeClassifier(max_depth=3, random_state=0).fit(x, y)\nend = time() - start\nscore_ = tree.score(x, y)\nDecisionBoundaryDisplay.from_estimator(tree, x, cmap=cm, alpha=0.8, ax=ax2, eps=0.5)\n# ax2.scatter(x[:, 0], x[:, 1], c=y, cmap=cm_bright, edgecolors=\"k\", alpha=0.2)\nax2.set_title(\"Decision Tree\\n Accuracy:{}%, Time: {}s\".format(round(score_*100), round(end, 4)))\nax2.set_xlim(0, 1)\nax2.set_ylim(0, 1)\nax2.set_xticks(())\nax2.set_yticks(())\n\n# Plot 3: DPDTreeClassifier\nstart = time()\ndpd_tree = DPDTreeClassifier(max_depth=3, random_state=0, cart_nodes_list=(8,)).fit(\n    x, y\n)\nend = time() - start\nscore_ = dpd_tree.score(x, y)\nDecisionBoundaryDisplay.from_estimator(dpd_tree, x, cmap=cm, alpha=0.8, ax=ax3, eps=0.5)\n# ax3.scatter(x[:, 0], x[:, 1], c=y, cmap=cm_bright, edgecolors=\"k\", alpha=0.2)\nax3.set_xlim(0, 1)\nax3.set_ylim(0, 1)\nax3.set_xticks(())\nax3.set_yticks(())\nax3.set_title(\"DP Decision Tree\\n Accuracy:{}%, Time: {}s\".format(round(score_*100), round(end, 4)))\n\n\nDecisionBoundaryDisplay.from_estimator(dpd_tree, x, cmap=cm, alpha=0.8, ax=ax4, eps=0.5)\n# ax3.scatter(x[:, 0], x[:, 1], c=y, cmap=cm_bright, edgecolors=\"k\", alpha=0.2)\nax4.set_xlim(0, 1)\nax4.set_ylim(0, 1)\nax4.set_xticks(())\nax4.set_yticks(())\nax4.set_title(\"Opt Decision Tree\\n Accuracy:100%, Time: 92s\")\n\n\n# Adjust layout and save figure\nplt.tight_layout()\nplt.savefig(\"patho_bounds_comparison\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}