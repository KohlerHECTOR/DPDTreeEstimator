{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# A Pathological Dataset\nA Dataset where the base :class:`sklearn.tree.DecisionTreeClassifier` fails.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from time import time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom dpdt import DPDTreeClassifier\n\n\ndef create_pathological_dataset(n_samples=1000):\n    # Generate random points\n    X = np.random.default_rng(42).random((n_samples, 2))\n    y = np.zeros(n_samples)\n\n    # Define regions for class 1 (checkerboard pattern)\n    class_1_mask = (\n        ((X[:, 0] < 0.5) & (X[:, 1] < 0.5))\n        | ((X[:, 0] >= 0.5) & (X[:, 1] >= 0.5))\n        | ((X[:, 0] < 0.25) & (X[:, 1] >= 0.5))\n        | ((X[:, 0] >= 0.75) & (X[:, 1] < 0.5))\n    )\n\n    # Assign labels\n    y[class_1_mask] = 1\n\n    return X, y\n\n\n# Create dataset\nx, y = create_pathological_dataset(10_000)\n\n# Create meshgrid\nfeature_1, feature_2 = np.meshgrid(\n    np.linspace(x[:, 0].min(), x[:, 0].max()), np.linspace(x[:, 1].min(), x[:, 1].max())\n)\ngrid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\n\ncm = plt.cm.RdBu\ncm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n\n# Create figure with 4 subplots\nfig, axs = plt.subplots(1, 4, figsize=(20, 4))\n\n# Plot 1: Pathological dataset\naxs[0].scatter(x[:, 0], x[:, 1], c=y, cmap=cm_bright, edgecolor=\"black\", s=10)\naxs[0].set_title(\"Pathological Dataset\\n  \", fontsize=25)\naxs[0].set_xlim(0, 1)\naxs[0].set_ylim(0, 1)\naxs[0].set_xticks(())\naxs[0].set_yticks(())\n\n# Plot 2: DecisionTreeClassifier\nstart = time()\ntree = DecisionTreeClassifier(max_depth=3, random_state=0).fit(x, y)\nend = time() - start\nscore_ = tree.score(x, y)\nDecisionBoundaryDisplay.from_estimator(tree, x, cmap=cm, alpha=0.8, ax=axs[1], eps=0.5)\naxs[1].set_title(\n    f\"Decision Tree\\nAccuracy: {score_*100}%\\nTime: {end:.4f}s\", fontsize=20\n)\naxs[1].set_xlim(0, 1)\naxs[1].set_ylim(0, 1)\naxs[1].set_xticks(())\naxs[1].set_yticks(())\n\n# Plot 3: DPDTreeClassifier\nstart = time()\ndpd_tree = DPDTreeClassifier(max_depth=3, random_state=0, cart_nodes_list=(8,)).fit(\n    x, y\n)\nend = time() - start\nscore_ = dpd_tree.score(x, y)\nDecisionBoundaryDisplay.from_estimator(\n    dpd_tree, x, cmap=cm, alpha=0.8, ax=axs[2], eps=0.5\n)\naxs[2].set_xlim(0, 1)\naxs[2].set_ylim(0, 1)\naxs[2].set_xticks(())\naxs[2].set_yticks(())\naxs[2].set_title(\n    f\"DP Decision Tree\\nAccuracy: {score_*100}%\\nTime: {end:.4f}s\", fontsize=20\n)\n\n# Plot 4: Opt Decision Tree (placeholder)\nDecisionBoundaryDisplay.from_estimator(\n    dpd_tree, x, cmap=cm, alpha=0.8, ax=axs[3], eps=0.5\n)\naxs[3].set_xlim(0, 1)\naxs[3].set_ylim(0, 1)\naxs[3].set_xticks(())\naxs[3].set_yticks(())\naxs[3].set_title(\"Opt Decision Tree\\nAccuracy: 100%\\nTime: 92s\", fontsize=20)\n\n# Adjust layout and save figure\nplt.tight_layout()\nplt.savefig(\"patho_bounds_comparison\", dpi=300, bbox_inches=\"tight\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}