{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Multi-class Gradient Boosting Trees\nWe compare gradient boosting with DPDT against\ngradient boosting with CART.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.datasets import make_gaussian_quantiles\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom dpdt import DPDTreeClassifier, GradientBoostingDPDTClassifier\n\nX, y = make_gaussian_quantiles(\n    n_samples=2_000, n_features=10, n_classes=3, random_state=1\n)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, train_size=0.7, random_state=42\n)\nn_estimators = 50\nweak_cart = DecisionTreeClassifier(max_depth=3, random_state=42)\nweak_dpdt = DPDTreeClassifier(max_depth=3)  # Not that weak\ngb_dpdt = GradientBoostingDPDTClassifier(n_estimators=n_estimators)\ngb_cart = GradientBoostingDPDTClassifier(n_estimators=n_estimators, use_default_dt=True)\n\ngb_dpdt.fit(X_train, y_train)\ngb_cart.fit(X_train, y_train)\n\n\ndummy_clf = DummyClassifier()\n\n\ndef misclassification_error(y_true, y_pred):\n    return 1 - accuracy_score(y_true, y_pred)\n\n\nweak_carts_misclassification_error = misclassification_error(\n    y_test, weak_cart.fit(X_train, y_train).predict(X_test)\n)\n\nweak_dpdts_misclassification_error = misclassification_error(\n    y_test, weak_dpdt.fit(X_train, y_train).predict(X_test)\n)\n\nprint(\n    \"DecisionTreeClassifier's misclassification_error: \"\n    f\"{weak_carts_misclassification_error:.3f}\"\n)\n\nprint(\n    \"DPDTreeClassifier's misclassification_error: \"\n    f\"{weak_dpdts_misclassification_error:.3f}\"\n)\n\nboosting_errors_dpdt = pd.DataFrame(\n    {\n        \"Number of trees\": range(1, gb_dpdt.n_estimators + 1),\n        \"GB-DPDT\": [\n            misclassification_error(y_test, y_pred)\n            for y_pred in gb_dpdt.staged_predict(X_test)\n        ],\n    }\n).set_index(\"Number of trees\")\nax = boosting_errors_dpdt.plot()\nax.set_ylabel(\"Misclassification error on test set\")\nax.set_title(\"Convergence of GB-DPDT algorithm\")\n\nplt.plot(\n    range(1, gb_cart.n_estimators + 1),\n    [\n        misclassification_error(y_test, y_pred)\n        for y_pred in gb_cart.staged_predict(X_test)\n    ],\n)\n\nplt.plot(\n    [boosting_errors_dpdt.index.min(), boosting_errors_dpdt.index.max()],\n    [weak_carts_misclassification_error, weak_carts_misclassification_error],\n    color=\"tab:orange\",\n    linestyle=\"dotted\",\n)\n\nplt.plot(\n    [boosting_errors_dpdt.index.min(), boosting_errors_dpdt.index.max()],\n    [weak_dpdts_misclassification_error, weak_dpdts_misclassification_error],\n    color=\"tab:blue\",\n    linestyle=\"dashed\",\n)\n\nplt.legend([\"GB-DPDT\", \"GB-CART\", \"DecisionTreeClassifier\", \"DPDTreeClassifier\"], loc=1)\nplt.savefig(\"gb_boosting_compare\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}