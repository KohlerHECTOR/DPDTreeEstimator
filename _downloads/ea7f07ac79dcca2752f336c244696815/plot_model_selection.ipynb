{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Benchmarking DPDT\nBenchmarking DPDT using datasets from https://arxiv.org/abs/2207.08815.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from time import time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport openml\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom dpdt import DPDTreeClassifier\n\n\ndef plot_benchmark_results(*benchmark_results, names=None):\n    n_results = len(benchmark_results)\n    if names is None:\n        names = [f\"Model {i+1}\" for i in range(n_results)]\n\n    n_datasets = len(benchmark_results[0])\n    n_cols = 8\n    n_rows = (n_datasets + n_cols - 1) // n_cols\n\n    fig, axs = plt.subplots(n_rows, n_cols, figsize=(3 * n_cols, 3 * n_rows))\n    fig.suptitle(\"Benchmark Results\")\n\n    # Flatten the axes array for easier iteration\n    axs = axs.flatten()\n\n    colors = plt.cm.rainbow(np.linspace(0, 1, n_results))\n\n    # Iterate through the datasets\n    for i, dataset_name in enumerate(benchmark_results[0].keys()):\n        ax = axs[i]\n\n        for j, (result, name) in enumerate(zip(benchmark_results, names)):\n            data = result[dataset_name]\n            ax.plot(\n                data[\"lengths\"],\n                data[\"scores\"],\n                color=colors[j],\n                label=name + \" \" + str(round(data[\"time\"], 3)) + \"s\",\n            )\n\n        # Set title and labels\n        ax.set_title(dataset_name, fontsize=8)\n        ax.set_xlabel(\"Tree Length\", fontsize=6)\n        ax.set_ylabel(\"Score\", fontsize=6)\n\n        # Set tick label size\n        ax.tick_params(axis=\"both\", which=\"major\", labelsize=6)\n\n        # Add legend\n        ax.legend(fontsize=6)\n\n    # Remove any unused subplots\n    for j in range(i + 1, len(axs)):\n        fig.delaxes(axs[j])\n\n    plt.tight_layout()\n    plt.savefig(\"benchmark_classif\")\n\n\ndef get_pareto_front_cart(clf_kwargs, X_train, y_train, X_test, y_test):\n    clf = DecisionTreeClassifier(**clf_kwargs)\n    path = clf.cost_complexity_pruning_path(X_train, y_train)\n    ccp_alphas, _ = path.ccp_alphas, path.impurities\n    scores = []\n    lengths = []\n    for ccp_alpha in ccp_alphas:\n        print(ccp_alpha)\n        clf = DecisionTreeClassifier(ccp_alpha=ccp_alpha, **clf_kwargs)\n        clf.fit(X_train, y_train)\n        scores.append(clf.score(X_test, y_test))\n        lengths.append(clf.decision_path(X_test).sum(axis=1).mean() - 1)\n    return (scores, lengths)\n\n\ndef benchmark(clf_cls, clf_kwargs):\n    benchmark_suite = openml.study.get_suite(337)  # obtain the benchmark suite\n    res_dict = {}\n    for _, task_id in enumerate(\n        benchmark_suite.tasks, start=8\n    ):  # iterate over half of tasks  # iterate over half of tasks\n        task = openml.tasks.get_task(\n            task_id,\n            download_data=False,\n            download_qualities=False,\n            download_features_meta_data=False,\n        )  # download the OpenML task\n        dataset = task.get_dataset()\n        X, y, _, _ = dataset.get_data(\n            dataset_format=\"dataframe\", target=dataset.default_target_attribute\n        )\n        X_train, X_test, y_train, y_test = train_test_split(\n            X.to_numpy(), y.to_numpy(), test_size=0.5, random_state=42\n        )\n\n        if clf_cls is DPDTreeClassifier:\n            start = time()\n            clf = clf_cls(**clf_kwargs)\n            clf.fit(X_train, y_train)\n            scores, lengths = clf.get_pareto_front(X_test, y_test)\n            end = time() - start\n        elif clf_cls is DecisionTreeClassifier:\n            start = time()\n            scores, lengths = get_pareto_front_cart(\n                clf_kwargs, X_train, y_train, X_test, y_test\n            )\n            end = time() - start\n        else:\n            raise AssertionError(\n                \"clf_cls should be DecisionTreeClassifier or DPDTreeClassifier\"\n            )\n\n        res_dict[dataset.name] = {\"scores\": scores, \"lengths\": lengths, \"time\": end}\n    return res_dict\n\n\ndpdt_kwargs = dict(max_depth=4, n_jobs=\"best\")\ncart_kwargs = dict(max_depth=4)\nres_dpdt = benchmark(DPDTreeClassifier, dpdt_kwargs)\nres_cart = benchmark(DecisionTreeClassifier, cart_kwargs)\n\nplot_benchmark_results(\n    res_dpdt, res_cart, names=[\"DPDTreeClassifier\", \"DecisionTreeClassifier\"]\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}